# üéÆ Game Engagement Prediction App

## üì¶ Dependencias Necessarias

```python
pip install -r requirements.txt
```

## üéØ Objetivo do Projeto
Prever com alta precis√£o o n√≠vel de engajamento (Alto/Baixo) que um jogo ter√° com os jogadores, analisando:

- Comportamento do jogador (horas jogadas, frequ√™ncia semanal)
- Caracter√≠sticas do jogo (g√™nero, dificuldade)
- Progresso do jogador (n√≠vel atingido, n¬∫ de conquistas)

## üîç Sele√ß√£o do Modelo

Ap√≥s extensiva avalia√ß√£o comparativa entre diversos algoritmos de Machine Learning, o **Ada Boost Classifier** demonstrou o melhor desempenho, sendo em seguida otimizado resultando nos seguintes valores de par√¢metros e m√©tricas:

```{python}
AdaBoostClassifier(
                algorithm='SAMME.R',       # Vers√£o real do algoritmo AdaBoost
                base_estimator=None,        # Por padr√£o usa DecisionTree com max_depth=1 (stump)
                learning_rate=1.0,          # Taxa de aprendizado (contribui√ß√£o de cada modelo)
                n_estimators=50,           # N√∫mero de stumps (modelos fracos)
                random_state=42             # Reprodutibilidade
            )
```
| M√©trica       | Valor | Interpreta√ß√£o                                                                 |
|--------------|-------|-------------------------------------------------------------------------------|
| **F1-Score** | 0.88  | **"Harmonia" entre precis√£o e recall** - Pontua√ß√£o balanceada considerando ambos os aspectos |
| **Acur√°cia** | 0.87  | **Acertos totais** - Percentual geral de classifica√ß√µes corretas              |
| **Precis√£o** | 0.83  | **Confian√ßa nos positivos** - Quando prev√™ "Alto Engajamento", acerta 83% das vezes |
| **Sencibilidade**   | 0.93  | **Cobertura de positivos** - Detecta 93% dos casos reais de Alto Engajamento  |


## üí° Conhecendo o Gradient Boosting Classifier

O **Ada Boost Classifier** foi selecionado como algoritmo principal por oferecer o melhor balanceamento entre desempenho preditivo e robustez estat√≠stica. Suas caracter√≠sticas t√©cnicas se alinham perfeitamente com nosso cen√°rio de dados:

### üéØ Mecanismo de Funcionamento do Ada Boost

1. **Passo Inicial - Base Simples**
   
  - Come√ßa com um modelo fraco (ex: √°rvore de decis√£o rasa - stump)
  - Todos os exemplos t√™m peso igual inicialmente

2. **Processo Iterativo - Aprendizado com Erros**
   
   *Primeira Itera√ß√£o*:
     - O stump faz predi√ß√µes iniciais
     - Erros s√£o identificados e os exemplos mal classificados recebem mais peso

   *Itera√ß√µes Seguintes*:
     - Cada novo stump foca nos exemplos mais dif√≠ceis (com maior peso)
     - Modelos subsequentes "herdam" os erros corrigidos anteriormente

4. **Mecanismo de Peso**
   
  - **Peso dos Exemplos**: Aumenta para casos mal classificados
  - **Peso dos Modelos**: Stumps mais precisos t√™m maior influ√™ncia no voto final

4. **Resultado Final - Voto Ponderado**
   
  - Combina todas as previs√µes dos stumps
  - Cada contribui√ß√£o √© ponderada pela precis√£o do modelo

5. **Vantagens Chave**
   
  - Foco autom√°tico nos casos mais dif√≠ceis
  - Simples e eficaz para problemas bin√°rios
  - Menos propenso a overfitting que algoritmos complexos
            
## üèÜ Comparative Model Performance Analysis

| Rank | Model                          | Acur√°cia    | AUC       | Sencibilidade    | Precis√£o | F1-Score   | Tempo de Treinamento|
|------|--------------------------------|-------------|-----------|------------------|-----------|------------|---------------|
| ü•á   | **Ada Boost Classifier**        |    **0.8719**	  |  *0.9156*	  |  	**0.9316**		     |  0.8324		  |  **0.8792**	  |  	0.6960
| ü•à   | *Gradient Boosting Classifier*	|    *0.8711*	  |  **0.9164**	  |  	*0.9230*	       |  	*0.8365*	  |  	*0.8776*	  |  	1.8600
| ü•â   | Light Gradient Boosting Machine|	  0.8707	  |  0.9134	  |  	0.9192	   	  |  0.8381		  |  **0.8767**	  |  	2.0800


### Legenda:
- **Negrito** = Melhor resultado na m√©trica
- *It√°lico* = Segundo melhor resultado

Outro fator que influenciou na escolha do AdaBoost Classifier foi a distribui√ß√£o de import√¢ncia das vari√°veis. No Gradient Boosting Classifier, a vari√°vel 'SessionsPerWeek' apresentava 97% de import√¢ncia, reduzindo 'PlayTimeHour' a uma relev√¢ncia quase nula - um padr√£o inadequado, pois: um jogador pouco engajado pode ter v√°rias sess√µes semanais mas com poucas horas jogadas em cada, enquanto um jogador altamente engajado pode acumular muitas horas de jogo em poucas sess√µes prolongadas. O AdaBoost, ao distribuir melhor essa import√¢ncia, captura essa nuance comportamental de forma mais equilibrada.

## üöÄ Experimente Agora!
Acesse a vers√£o interativa do modelo:  
[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://nivelengajamentojogo.streamlit.app).
