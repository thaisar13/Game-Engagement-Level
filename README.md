# üéÆ Game Engagement Prediction App

## üì¶ Dependencias Necessarias

```python
pip install -r requirements.txt
```

## üéØ Objetivo do Projeto
Prever com alta precis√£o o n√≠vel de engajamento (Alto/Baixo) que um jogo ter√° com os jogadores, analisando:

- Comportamento do jogador (horas jogadas, frequ√™ncia semanal)
- Caracter√≠sticas do jogo (g√™nero, dificuldade)
- Progresso do jogador (n√≠vel atingido, n¬∫ de conquistas)

## üîç Sele√ß√£o do Modelo

Ap√≥s extensiva avalia√ß√£o comparativa entre diversos algoritmos de Machine Learning, o **Gradient Boosting Classifier** demonstrou o melhor desempenho, sendo em seguida otimizado resultando nos seguintes valores de par√¢metros e m√©tricas:

```{python}
GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=6,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.0005, min_samples_leaf=3,
                           min_samples_split=4, min_weight_fraction_leaf=0.0,
                           n_estimators=60, n_iter_no_change=None,
                           random_state=42, subsample=0.95, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
```
| M√©trica       | Valor | Interpreta√ß√£o                                                                 |
|--------------|-------|-------------------------------------------------------------------------------|
| **F1-Score** | 0.88  | **"Harmonia" entre precis√£o e recall** - Pontua√ß√£o balanceada considerando ambos os aspectos |
| **Acur√°cia** | 0.87  | **Acertos totais** - Percentual geral de classifica√ß√µes corretas              |
| **Precis√£o** | 0.84  | **Confian√ßa nos positivos** - Quando prev√™ "Alto Engajamento", acerta 83% das vezes |
| **Sencibilidade**   | 0.92  | **Cobertura de positivos** - Detecta 93% dos casos reais de Alto Engajamento  |


## üí° Conhecendo o Gradient Boosting Classifier

O **Gradient Boosting Classifier** foi selecionado como algoritmo principal por oferecer o melhor balanceamento entre desempenho preditivo e robustez estat√≠stica. Suas caracter√≠sticas t√©cnicas se alinham perfeitamente com nosso cen√°rio de dados:

### üéØ Mecanismo de Funcionamento do Gradient Boosting
1. **Otimiza√ß√£o por Gradiente**:

O modelo funciona atrav√©s de um processo iterativo que:

   - Come√ßa com uma previs√£o inicial simples (ex: m√©dia)
   - Calcula os erros (gradientes) entre previs√µes e valores reais
   - Treina uma nova √°rvore para prever esses erros
   - Atualiza as previs√µes com pequenos passos controlados (learning_rate=0.001)
   - Repete por 60 itera√ß√µes (n_estimators=60)

F√≥rmula Chave:
Nova Previs√£o = Previs√£o Anterior + learning_rate * Previs√£o da √Årvore-Atual

2. **Aprendizado Sequencial em Camadas**:

Passo-a-passo:
   1) Primeira √°rvore:
      - Faz previs√£o inicial (baseline)
      - Calcula erros (valores reais - previs√µes)

   2) √Årvores seguintes:
      - Cada nova √°rvore √© treinada nos erros residuais das anteriores
      - Erros grandes recebem mais aten√ß√£o
      - Ajustes s√£o feitos gradualmente (passos pequenos de 0.001)

   3) Combina√ß√£o final:
      - Soma ponderada de todas as 60 √°rvores
      - Resultado final balanceado

3. **Regulariza√ß√£o Nativa (Anti-Overfiting)**:

T√©cnicas implementadas:

   a) Limita√ß√£o de Profundidade (max_depth=6)
      - √Årvores n√£o podem ficar muito complexas
      - Previne memoriza√ß√£o dos dados

   b) Subamostragem (subsample=0.95)
      - Cada √°rvore usa apenas 95% dos dados aleat√≥rios
      - Aumenta diversidade das √°rvores

   c) Sele√ß√£o de Features (max_features='log2')
      - Considera apenas ‚àön features em cada divis√£o
      - Reduz correla√ß√£o entre √°rvores


## üèÜ Comparative Model Performance Analysis

| Rank | Model                     | Acur√°cia    | AUC       | Sencibilidade    | Precis√£o | F1-Score   | Tempo de Treinamento|
|------|---------------------------|-------------|-----------|-----------|-----------|------------|---------------|
| ü•á   | **Gradient Boosting**     | **0.8720**  | *0.9167* | *0.9241*   | 0.8371    | *0.8784*  | 1.6050s      |
| ü•à   | *Ada Boost Classifier*    | *0.8718*    | 0.9156   | **0.9316** | 0.8323    | **0.8792**| 0.4470s      |
| ü•â   | LightGBM                  | 0.8712     | 0.9128    | 0.9192     | *0.8390*  | 0.8772    | 1.5580s      |
| 4Ô∏è‚É£   | Random Forest             | 0.8705     | 0.9082    | 0.9185     | 0.8382    | 0.8765    | 1.8570s      |
| 5Ô∏è‚É£   | Ridge Classifier          | 0.8716     | **0.9169**| 0.9063     | **0.8477**| 0.8760    | **0.0410s**      |

### Legenda:
- **Negrito** = Melhor resultado na m√©trica
- *It√°lico* = Segundo melhor resultado

Note que embora o Ada Boost Classifier tenha apresentado o melhor resultado para a m√©trica F1-Score, que √© uma m√©trica que balanceia os resultados de acerto do modelo classificador, o Gradient Boosting apresentou um resultado sutilmente melhor em AUC, o que indica que esse modelo apresenta uma maior capacidade de distin√ß√£o das classe, e como a vari√°vel resposta n√£o paresenta limites muito bem definidos, o Gradient Boosting foi o modelo escolhido.

## üöÄ Experimente Agora!
Acesse a vers√£o interativa do modelo:  
[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://nivelengajamentojogo.streamlit.app).
