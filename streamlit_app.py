# streamlit_app.py
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import os
from sklearn.preprocessing import StandardScaler
import plotly.express as px  


# Configura√ß√µes da p√°gina
st.set_page_config(
    page_title="Game Engagement Predictor",
    layout="wide",
    page_icon="üéÆ",
    initial_sidebar_state="expanded"
)

# Fun√ß√µes de pr√©-processamento
def preprocess_data(df):
    # Criar c√≥pia para n√£o modificar o original
    df_processed = df.copy()
    
    # Filtrar apenas n√≠veis Low e High
    df_processed = df_processed[df_processed['EngagementLevel'].isin(['Low', 'High'])]
    
    # Converter EngagementLevel para bin√°rio
    df_processed['EngagementLevel'] = df_processed['EngagementLevel'].map({'Low': 0, 'High': 1})
    
    # Dummyfica√ß√£o
    cat_vars = ['GameGenre', 'GameDifficulty', 'InGamePurchases']
    df_processed = pd.get_dummies(df_processed, columns=cat_vars, drop_first=True)
    
    # Padroniza√ß√£o
    scaler = StandardScaler()
    numeric_vars = ['Age', 'SessionsPerWeek', 'PlayTimeHours', 
                   'AchievementsUnlocked', 'PlayerLevel']
    df_processed[numeric_vars] = scaler.fit_transform(df_processed[numeric_vars])
    
    return df_processed, scaler

# Carregar e preparar dados
@st.cache_data
def load_data():
    try:
        # Carregar dados originais
        dados = pd.read_csv("online_gaming_behavior_dataset.csv")
        
        # Filtrar apenas Low e High para visualiza√ß√£o tamb√©m
        dados = dados[dados['EngagementLevel'].isin(['Low', 'High'])]
        
        # Criar vers√£o para visualiza√ß√£o (remove colunas n√£o usadas)
        cols_to_keep = ['Age', 'SessionsPerWeek', 'PlayTimeHours', 
                       'AchievementsUnlocked', 'PlayerLevel', 'EngagementLevel',
                       'GameGenre', 'GameDifficulty', 'InGamePurchases']
        
        dados_vis = dados[cols_to_keep].copy()
        
        # Processar dados para modelagem
        dados_prep, scaler = preprocess_data(dados_vis)
        
        return dados_vis, dados_prep, scaler
    
    except Exception as e:
        st.error(f"Erro ao carregar dados: {e}")
        return None, None, None

# Carregar os dados
dados_vis, dados_prep, scaler = load_data()

# Barra lateral - Navega√ß√£o
st.sidebar.title("Menu")
pagina = st.sidebar.radio(
    "Se√ß√µes:",
    ["üè† Vis√£o Geral", "üîç An√°lise Explorat√≥ria", "‚öôÔ∏è Pr√©-processamento", "ü§ñ Modelo Preditivo", "üîÆ Fazer Previs√£o"]
)

# P√°gina 1: Vis√£o Geral
if pagina == "üè† Vis√£o Geral":
    st.title("üéÆ An√°lise Preditiva de Engajamento em Jogos")
    st.markdown("---")
    
    # Se√ß√£o de introdu√ß√£o com colunas
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.header("üìã Vis√£o Geral do Projeto")
        st.markdown("""
        **Objetivo:** Desenvolver um modelo preditivo para classificar o n√≠vel de engajamento de jogadores  
        **Aplica√ß√£o:** Auxiliar desenvolvedores a identificar padr√µes de comportamento e melhorar a experi√™ncia do usu√°rio  
        **Abordagem:** An√°lise explorat√≥ria + Modelagem supervisionada (classifica√ß√£o bin√°ria)
        """)
        
    #with col2:
     #   st.image("https://cdn-icons-png.flaticon.com/512/2936/2936886.png", width=100)
    
    st.markdown("---")
    
    # Se√ß√£o de dados com expansores
    with st.expander("üîç **Fonte de Dados**", expanded=True):
        st.markdown("""
        - **Dataset:** [Online Gaming Behavior Dataset](https://www.kaggle.com/datasets/rabieelkharoua/predict-online-gaming-behavior-dataset)
        - **Vari√°veis originais:** 13
        - **Amostra final:** {:,} jogadores (Low: {:,} | High: {:,})
        """.format(
            len(dados_vis),
            sum(dados_vis['EngagementLevel'] == 'Low'),
            sum(dados_vis['EngagementLevel'] == 'High')
        ))
    
    # Se√ß√£o t√©cnica com tabs
    tab1, tab2, tab3 = st.tabs(["üìä M√©tricas", "üß† Modelagem", "‚öôÔ∏è Engenharia de Features"])
    
    with tab1:
        st.subheader("Desempenho do Modelo (Gradient Boosting)")
        col1, col2, col3, col4 = st.columns(4)
        
        col1.metric("F1-Score", "0.88", help="M√©trica balanceada entre precis√£o e recall")
        col2.metric("Acur√°cia", "0.87", help="Percentual total de acertos")
        col3.metric("Precis√£o", "0.84", help="Quando prev√™ Alto Engajamento, acerta 84%")
        col4.metric("Recall", "0.92", help="Identifica 92% dos casos reais de Alto Engajamento")
        

    with tab2:
        st.markdown("""
        **Processo de Modelagem:**
        1. **Pr√©-processamento:** Filtragem, codifica√ß√£o e normaliza√ß√£o
        2. **Sele√ß√£o de Modelos:** Compara√ß√£o de 15 algoritmos via PyCaret (seleciondo o Gradient Boosting)
        3. **Tunagem:** Otimiza√ß√£o de hiperpar√¢metros para melhor F1-Score
        4. **Valida√ß√£o:** Teste com holdout de 25% dos dados
        
        **Algoritmos Testados:**""")

        # Dados da tabela
        data = {
            "Model": [
                "Gradient Boosting Classifier",
                "Ada Boost Classifier",
                "Light Gradient Boosting Machine",
                "Random Forest Classifier",
                "Ridge Classifier",
                "Linear Discriminant Analysis",
                "Naive Bayes",
                "Quadratic Discriminant Analysis",
                "Logistic Regression",
                "SVM - Linear Kernel",
                "Extra Trees Classifier",
                "Extreme Gradient Boosting",
                "K Neighbors Classifier",
                "Decision Tree Classifier",
                "Dummy Classifier"
            ],
            "F1-Score": [0.8784, 0.8792, 0.8772, 0.8765, 0.8760, 0.8760, 0.8748, 0.8745, 0.8734, 0.8721, 0.8714, 0.8677, 0.8548, 0.7823, 0.6669],
            "Acur√°cia": [0.8720, 0.8718, 0.8712, 0.8705, 0.8716, 0.8716, 0.8709, 0.8705, 0.8700, 0.8667, 0.8663, 0.8624, 0.8499, 0.7826, 0.5003],
            "Precis√£o": [0.8371, 0.8323, 0.8390, 0.8382, 0.8477, 0.8477, 0.8493, 0.8493, 0.8516, 0.8388, 0.8399, 0.8362, 0.8284, 0.7837, 0.5003],
            "Recall": [0.9241, 0.9316, 0.9192, 0.9185, 0.9063, 0.9063, 0.9020, 0.9012, 0.8965, 0.9084, 0.9053, 0.9018, 0.8831, 0.7813, 1.0000]
        }
        
        df = pd.DataFrame(data)
        
        st.write("Tabela comparativa de desempenho (sem AUC, Kappa, MCC e Tempo de Treinamento)")
        st.dataframe(df, hide_index=True, use_container_width=True)
        
        st.markdown("""
        <style>
            .dataframe td {
                text-align: center !important;
            }
            .dataframe th {
                text-align: center !important;
            }
        </style>
        """, unsafe_allow_html=True)
            
            
    with tab3:
        st.markdown("""
        **Principais Features:**
        1. SessionsPerWeek (Import√¢ncia: 98%)
        2. PlayerLevel (2%)
        3. AchievementsUnlocked (2%)
        
        **Transforma√ß√µes:**
        - One-Hot Encoding nas vari√°veis categ√≥ricas
        - Standard Scaling na vari√°veis num√©ricas
        """)
    
    # Chamada para a√ß√£o
    st.markdown("---")
    st.success("üí° **Explore as outras se√ß√µes para an√°lises detalhadas e simula√ß√µes de previs√£o!**")

#```{python}
        #GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
        #                           learning_rate=0.001, loss='log_loss', max_depth=6,
       #                            max_features='log2', max_leaf_nodes=None,
      #                             min_impurity_decrease=0.0005, min_samples_leaf=3,
     #                              min_samples_split=4, min_weight_fraction_leaf=0.0,
    #                               n_estimators=60, n_iter_no_change=None,
   #                                random_state=42, subsample=0.95, tol=0.0001,
  #                                 validation_fraction=0.1, verbose=0,
 #                                  warm_start=False)
#```

 
    

# P√°gina 2: An√°lise Explorat√≥ria
elif pagina == "üîç An√°lise Explorat√≥ria":
    st.title("üîç An√°lise Explorat√≥ria dos Dados")
    st.markdown("---")
    
    if dados_vis is not None:
        st.header("üìä Dados Brutos (Amostra)")
        st.dataframe(dados_vis.head(), use_container_width=True)
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Total de Registros", len(dados_vis))
        with col2:
            st.metric("Vari√°veis Originais", len(dados_vis.columns))
    
    if dados_vis is not None:
        st.header("Distribui√ß√£o de Engajamento")
        
        # Gr√°fico de barras 
        fig, ax = plt.subplots(figsize=(10, 5))
        counts = dados_vis['EngagementLevel'].value_counts()
        counts.plot(kind='bar', color=['#FF6B6B', '#4ECDC4'], ax=ax)
        # Adicionando r√≥tulos e formata√ß√£o
        ax.set_title('Distribui√ß√£o dos N√≠veis de Engajamento', pad=20)
        ax.set_xlabel('N√≠vel de Engajamento')
        ax.set_ylabel('Contagem')
        ax.set_xticklabels(['Baixo (Low)', 'Alto (High)'], rotation=0)
        # Adicionando valores nas barras
        for i, v in enumerate(counts):
            ax.text(i, v + 5, str(v), ha='center', va='bottom', fontsize=12)
        st.pyplot(fig)

        st.markdown(""" Embora este seja o √∫nico gr√°fico apresentado, todas as vari√°veis categ√≥ricas analisadas seguem o mesmo padr√£o de distribui√ß√£o, 
        mantendo uma proporcionalidade equilibrada entre suas categorias que reflete quase que diretamente a quantidade de observa√ß√µes em cada classe.
        """)
        
        st.markdown("---")
        st.header("Rela√ß√£o Idade vs Tempo de Jogo")
        
        # Scatterplot
        fig, ax = plt.subplots(figsize=(12, 7))
        scatter = sns.scatterplot(
            data=dados_vis, 
            x='Age', 
            y='PlayTimeHours', 
            hue='EngagementLevel',
            palette={'Low': '#FF6B6B', 'High': '#4ECDC4'},
            s=100,  # Tamanho dos pontos aumentado
            alpha=0.7,  # Transpar√™ncia
            ax=ax
        )
        # Legenda
        handles, labels = ax.get_legend_handles_labels()
        ax.legend(handles, ['Baixo (Low)', 'Alto (High)'], title='Engajamento')
        # Adicionando t√≠tulo e r√≥tulos
        ax.set_title('Rela√ß√£o entre Idade e Tempo de Jogo por N√≠vel de Engajamento', pad=20)
        ax.set_xlabel('Idade (anos)')
        ax.set_ylabel('Horas Jogadas por Semana')
        st.pyplot(fig)
        
        st.markdown(""" Novamente, embora tenhamos destacado apenas este gr√°fico espec√≠fico, todas as an√°lises entre vari√°veis cont√≠nuas revelaram o mesmo padr√£o: 
        uma dispers√£o aleat√≥ria de pontos que n√£o indica qualquer correla√ß√£o significativa entre as vari√°veis analisadas nem com os n√≠veis de engajamento dos 
        jogadores.
        """)
        
        st.markdown("---")
        st.subheader("Matriz de Correla√ß√£o")
        
        # Matriz de correla√ß√£o
        fig, ax = plt.subplots(figsize=(12, 8))
        # Calculando a matriz de correla√ß√£o apenas para vari√°veis num√©ricas
        numeric_vars = dados_vis.select_dtypes(include=['int64', 'float64'])
        corr_matrix = numeric_vars.corr()
        # Criando o heatmap
        sns.heatmap(
            corr_matrix,
            annot=True,
            cmap='coolwarm',
            center=0,
            fmt='.2f',
            linewidths=0.5,
            ax=ax
        )
        # Ajustando o t√≠tulo
        ax.set_title('Correla√ß√£o entre Vari√°veis Num√©ricas', pad=20)
        st.pyplot(fig)
        
        st.markdown(""" As correla√ß√µes entre as vari√°veis num√©ricas s√£o notavelmente fracas (pr√≥ximas de zero em v√°rios casos), o que explica diretamente sua baixa 
        import√¢ncia no modelo de classifica√ß√£o do engajamento dos jogadores.
        """)
    
# P√°gina 3: Pr√©-processamento
elif pagina == "‚öôÔ∏è Pr√©-processamento":
    st.title("‚öôÔ∏è Pr√©-processamento dos Dados")
    st.markdown("---")
    
    if dados_prep is not None:
        st.header("Transforma√ß√µes Aplicadas")
        #st.markdown("""
        ### 1. Filtragem Inicial
       # - **Sele√ß√£o de categorias:** Mantivemos apenas os n√≠veis 'Low' e 'High' de engajamento
        #- **Justificativa:** A categoria 'Medium' foi exclu√≠da para criar um problema de classifica√ß√£o bin√°ria mais definido
        #- **Resultado:** Redu√ß√£o de {:.1%} no volume de dados (de {} para {} registros)
        #""".format(
        #    1 - len(dados_prep)/len(dados_orig),
        #    len(dados_orig),
        #    len(dados_prep)
        #)

        st.markdown("""
        ### 1. Sele√ß√£o de Features
        Foram removidas as seguintes vari√°veis:
        - **PlayerID:** Identificador √∫nico sem valor preditivo
        - **AvgSessionDurationMinutes:** Eliminada para evitar multicolinearidade com `SessionsPerWeek` e `PlayTimeHours`
        - **Gender e Location:** Removidas ap√≥s an√°lise de import√¢ncia de features por piorarem decimalmente o desempenho dos modelos testados
        """)

        st.markdown("""
        ### 2. Transforma√ß√£o de Vari√°veis
        **Vari√°vel Target:**
        - Codifica√ß√£o bin√°ria:
          - `Low` ‚Üí 0
          - `High` ‚Üí 1

        **Vari√°veis Categ√≥ricas (One-Hot Encoding):**
        ```python
        pd.get_dummies(columns=['GameGenre', 'GameDifficulty', 'InGamePurchases'], 
                      drop_first=True)
        ```
        - **Estrat√©gia:** `drop_first=True` para evitar a armadilha da vari√°vel dummy
        - **Resultado:** Adi√ß√£o de {} novas colunas
        """.format(len(dados_prep.columns) - 8))  # Ajuste o n√∫mero conforme suas vari√°veis

        st.markdown("""
        **Vari√°veis Num√©ricas:**
        ```python
        StandardScaler().fit_transform(['Age', 'SessionsPerWeek', 
                                      'PlayTimeHours', 'AchievementsUnlocked',
                                      'PlayerLevel'])
        ```
        - **Efeito:** Centraliza√ß√£o (Œº=0) e Escala (œÉ=1)
        - **Benef√≠cios:**
          - Melhor converg√™ncia para modelos sens√≠veis √† escala (SVM, Regress√£o Log√≠stica)
          - Import√¢ncia relativa compar√°vel entre features
        """)

        st.markdown("""
        ### 3. Valida√ß√£o do Pr√©-processamento
        - **Balanceamento de classes:** {:.1f}:{:.1f} (Low:High)
        - **Aus√™ncia de NaNs:** Confirmada ({} valores faltantes totais)
        """.format(
            *dados_prep['EngagementLevel'].value_counts(normalize=True).values,
            dados_prep.isna().sum().sum(),  
        ))

#        with st.expander("üîç Visualiza√ß√£o do Pipeline Completo"):
 #           st.image("https://miro.medium.com/max/1400/1*4PqYyZbws0N4yR0sFw3yJQ.png", 
  #                  caption="Exemplo de fluxo de pr√©-processamento", width=400)
        
        st.header("üìã Dados Pr√©-processados (Amostra)")
        st.dataframe(dados_prep.head(), use_container_width=True)
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Registros", len(dados_prep))
        with col2:
            st.metric("Vari√°veis", len(dados_prep.columns))

# P√°gina 4: Modelo Preditivo
elif pagina == "ü§ñ Modelo Preditivo":
    st.title("ü§ñ Modelo Preditivo: Gradient Boosting")
    st.markdown("---")

    st.header("Metodologia")
    st.markdown("""
    - **Framework:** PyCaret
    - **Sele√ß√£o de Modelos:** Compara√ß√£o com base no rankeamneto com o F1-Score, seguido do melhor desempenho geral entre as m√©tricas e desempatada pela AUC
    - **Melhor Modelo:** Gradient Boosting Classifier (tunado ap√≥s sele√ß√£o)
    - **M√©tricas:**
      - Acur√°cia: 87%
      - Sencibilidade: 92%
      - Precis√£o: 84%
      - F1-Score: 88%
      - AUC: 92%
    """)
    
    tab1, tab2 = st.tabs(["üîç Interpreta√ß√£o do Modelo", "üéØ Quem √© o Gradient Boosting?"])
    
    with tab1:
        st.header("üîç Interpreta√ß√£o do Modelo")
        try:
            model = joblib.load('model.pkl')
            st.success("‚úÖ Modelo carregado com sucesso!")
            
            st.markdown("""
            ### Significado das M√©tricas
            
            **Interpreta√ß√£o:**  
            
            O modelo demonstra um **bom desempenho geral** (Acur√°cia de 87%), com destaque para sua capacidade de:  
            
            - **Capturar casos Positivos**: Alta Sencibilidade (92%) indica que o modelo identifica efetivamente jogadores engajados (apenas 8% de falsos negativos)  
            - **Distinguir Classes**: AUC (√Årea sib a Curva ROC) de 92% revela excelente separa√ß√£o entre os jogadores de baixo engajamento dos de alto engajamento 
            - **Equil√≠brio**: F1-Score (88%) mostra boa harmonia entre Precis√£o e Recall  
            - **Chance de Erro**: Precis√£o (84%) sugere que, quando o modelo prev√™ "alto engajamento", h√° 16% de chance de ser falso positivo. Algo espera dada a 
            sobreposi√ß√£o natural nos padr√µes de engajamento e das vari√°veis preditoras apresentarem um poder limitado de discrimina√ß√£o  
            """)
            
            st.markdown(""" ### Import√¢ncia das Vari√°veis""")

            feature_importance = pd.DataFrame({
                'Feature': ['SessionsPerWeek', 'PlayerLevel', 'AchievementsUnlocked', 'PlayTimeHours','Age', 
                            'InGamePurchases_1', 'EngagementLevel', 'GameGenre_RPG', 'GameGenre_Simulation', 
                            'GameGenre_Sports', 'GameGenre_Strategy', 'GameDifficulty_Hard', 'GameDifficulty_Medium'],
                'Importance': [0.98, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
            })
            
            fig, ax = plt.subplots(figsize=(10,5))
            sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')
            st.pyplot(fig)
            
            st.markdown(""" Embora, por terem uma relev√£ncia t√£o baixa na classifica√ß√£o do engajamento do jogador, praticamente todas as vari√°veis,
            por exce√ß√£o de SessionPerWeek, poderiam ter sido descartadas do modelo final, mas como sua remo√ß√£o teve uma mudan√ßa quase que insignificante
            aos resultados, optou-se por deixar tais vari√°veis com o intuito de melhorar o desempenho da tunagem dos hiperpar√¢metros do modelo final.""")
    
            
        except Exception as e:
            st.error(f"Erro ao carregar modelo: {e}")

    with tab2:
        # Se√ß√£o 3: Conhecendo o Gradient Boosting
        st.header("üéØ Quem √© o Gradient Boosting?")
        st.markdown("""
        <div style="text-align: justify">
        O <strong>Gradient Boosting Classifier</strong> √© como um time de especialistas trabalhando em equipe, onde cada novo membro 
        aprende com os erros dos anteriores. Veja como ele se destaca:
        </div>
        """, unsafe_allow_html=True)
        
        # Explica√ß√£o visual em colunas
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("""
            ### üß† Como Funciona?
            1. **√Årvores Sequenciais**:  
               Cria uma s√©rie de √°rvores de decis√£o pequenas (weak learners)
            2. **Corre√ß√£o de Erros**:  
               Cada nova √°rvore foca nos res√≠duos (erros) da anterior
            3. **Combina√ß√£o Ponderada**:  
               Resultado final √© a soma das previs√µes de todas as √°rvores
            """)
            
            # st.image("https://miro.medium.com/v2/resize:fit:1400/1*_kqsmyUwK8v1gKi0tRGsCQ.gif", 
            #          caption="Fonte: Medium - Gradient Boosting em a√ß√£o")
        
        with col2:

            st.markdown("""
            ### üèÜ Crit√©rio de Sele√ß√£o do Modelo
            
            O modelo foi selecionado atrav√©s de uma an√°lise comparativa das m√©tricas de desempenho, considerando inicialmente os **5 melhores modelos com base no F1-Score**. Foi atribu√≠do um sistema de pontua√ß√£o por posi√ß√£o:
            
            - <b>1¬∫ lugar</b> em cada m√©trica: <b>+2 pontos</b>
            - <b>2¬∫ lugar</b>: <b>+1 ponto</b>
            
            <br>
            
            Ap√≥s essa avalia√ß√£o, os dois melhores modelos ficaram <b>empatados com 5 pontos cada</b>:
            
            <div style="margin-left: 20px;">
            
            <b>1. AdaBoost Classifier</b>  
               - ü•á <b>Melhor desempenho</b> em:  
                 ‚Ä¢ F1-Score  
                 ‚Ä¢ Sensibilidade (Recall)  
               - ü•à <b>Segunda melhor</b> acur√°cia  
            
            <b>2. Gradient Boosting</b>  
               - ü•á <b>Melhor desempenho</b> em:  
                 ‚Ä¢ Acur√°cia  
               - ü•à <b>Segundo melhor</b> em:  
                 ‚Ä¢ AUC  
                 ‚Ä¢ Sensibilidade (Recall)  
                 ‚Ä¢ F1-Score  
            </div>
            
            <h4>Crit√©rio de Desempate</h4>
            Como fator decisivo, foi considerado o <b>maior valor de AUC</b> (Area Under the Curve) do <i>Gradient Boosting</i>, uma vez que a vari√°vel resposta
            <b>n√£o apresenta limites bem definidos entre suas categorias</b>. Nesse contexto, um modelo com maior capacidade de <b>distinguir as classes</b> 
            (refletido pelo AUC mais alto) √© prefer√≠vel.
            
            """, unsafe_allow_html=True)
            st.success(" **Observa√ß√£o Final:üí°As diferen√ßas entre as m√©tricas dos dois modelos s√£o muito sutis, n√£o havendo um desempenho significativamente superior de um em rela√ß√£o ao outro. A escolha final priorizou a robustez na discrimina√ß√£o das categorias.**")
        # Detalhes t√©cnicos com expansor
        with st.expander("üßÆ A Matem√°tica por Tr√°s", expanded=False):
            st.markdown("""
            **Fun√ß√£o Objetivo**:
            ```
            F(x) = Œ≥‚ÇÅh‚ÇÅ(x) + Œ≥‚ÇÇh‚ÇÇ(x) + ... + Œ≥‚Çôh‚Çô(x)
            ```
            Onde:
            - `h‚Çô(x)`: √Årvore individual (weak learner)
            - `Œ≥‚Çô`: Peso de cada √°rvore (aprendido durante o treino)
            
            **Passo a Passo**:
            1. Inicia com predi√ß√£o ing√™nua (m√©dia)
            2. Calcula res√≠duos (erros) para cada observa√ß√£o
            3. Treina nova √°rvore para prever esses res√≠duos
            4. Atualiza o modelo com taxa de aprendizado (Œ∑)
            5. Repete at√© converg√™ncia ou limite de itera√ß√µes
            """)
        with st.expander("üîß Configura√ß√£o T√©cnica Detalhada", expanded=False):
            st.code("""
            GradientBoostingClassifier(
                ccp_alpha=0.0,                 # Sem poda de complexidade adicional
                criterion='friedman_mse',      # M√©todo para encontrar melhores splits (considera valores m√©dios)
                learning_rate=0.001,           # Taxa de aprendizado cuidadosa
                max_depth=6,                   # Profundidade controlada
                max_features='log2',           # Otimiza√ß√£o para muitas features
                min_samples_leaf=3,            # Preven√ß√£o de overfitting
                min_impurity_decrease=0.0005,  # Explica√ß√£o do mecanismo de poda autom√°tica
                n_estimators=60,               # N√∫mero ideal de √°rvores
                subsample=0.95,                # Stochastic Gradient Boosting
                random_state=42,               # Reprodutibilidade
                loss='log_loss'                # Para problemas de classifica√ß√£o
            )
            """, language='python')
        #st.markdown("""
        #<div style="background-color: #2e4057; padding: 15px; border-radius: 5px; color: white;">
        #<strong>üí° Curiosidade T√©cnica:</strong> Nosso modelo final combina <strong style="color:#f4d35e">150 dessas √°rvores</strong>, 
        #cada uma com profundidade m√°xima 4 (para evitar overfitting), usando taxa de aprendizado de 0.1.
        #</div>
        #""", unsafe_allow_html=True)
# P√°gina 5: Previs√£o com o Modelo
elif pagina == "üîÆ Fazer Previs√£o":
    st.title("üîÆ Simulador de Previs√£o de Engajamento")
    st.markdown("---")
    
    if dados_vis is not None and scaler is not None:
        st.header("üìã Insira os Dados do Jogador")
        
        col1, col2 = st.columns(2)
        
        with col1:
            age = st.slider("Idade", 15, 50, 23)
            play_time = st.slider("Horas Jogadas/Dia", 1, 12, 3)
            sessions = st.slider("Sess√µes por Semana", 1, 20, 13)
            level = st.slider("N√≠vel do Personagem", 1, 99, 25)
            
        with col2:
            achievements = st.slider("Conquistas Desbloqueadas", 0, 100, 30)
            difficulty = st.selectbox("Dificuldade do Jogo", ["Easy", "Medium", "Hard"], index=1)
            genre = st.selectbox("G√™nero do Jogo", ["Acition", "RPG", "Simulation", "Sports", "Strategy"])
            purchases = st.radio("Realizou Compras no Jogo", ["Sim", "N√£o"], horizontal=True)
           
        if st.button("üîç Prever N√≠vel de Engajamento", type="primary", use_container_width=True):
            try:                
                # 1. Carrega o pipeline
                pipeline = joblib.load('model.pkl')
                
                # 2. Prepara os dados J√Å CODIFICADOS como o modelo espera
                input_data = pd.DataFrame({
                    'Age': [age],
                    'PlayTimeHours': [play_time],
                    'SessionsPerWeek': [sessions],
                    'PlayerLevel': [level],
                    'AchievementsUnlocked': [achievements],
                    
                    # Vari√°veis categ√≥ricas J√Å CODIFICADAS (one-hot)
                    'GameDifficulty_Hard': [1 if difficulty == "Hard" else 0],
                    'GameDifficulty_Medium': [1 if difficulty == "Medium" else 0],
                    'GameGenre_RPG': [1 if genre == "RPG" else 0],
                    'GameGenre_Simulation': [1 if genre == "Simulation" else 0],
                    'GameGenre_Sports': [1 if genre == "Sports" else 0],
                    'GameGenre_Strategy': [1 if genre == "Strategy" else 0],
                    'InGamePurchases_1': [1 if purchases == "Sim" else 0]
                })
                
                # 3. Garante a ordem correta das colunas
                input_data = input_data[pipeline.named_steps['actual_estimator'].feature_names_in_]
                st.write("Classes do modelo:", pipeline.classes_)
                st.write("Feature names:", pipeline.named_steps['actual_estimator'].feature_names_in_)
                st.write(pipeline.named_steps)
                try:
                    # 4. Faz a previs√£o (o imputer vai lidar com quaisquer valores faltantes)
                    prediction = pipeline.predict(input_data)[0]
                    proba = pipeline.predict_proba(input_data)[0][1]
                    
                    st.success(f"Previs√£o: {prediction} (Probabilidade: {proba:.2%})")
                    
                except Exception as e:
                    st.error(f"Erro na previs√£o: {str(e)}")
                    st.write("Dados enviados:", input_data)
                    st.write("Features esperadas:", pipeline.named_steps['actual_estimator'].feature_names_in_)
                
                # Exibir resultados
                st.markdown("---")
                st.subheader("üìä Resultado da Previs√£o")
                
                if prediction == 1:
                    st.success(f"## Alto Engajamento ({proba:.1%} de confian√ßa)")
                    st.balloons()
                else:
                    st.warning(f"## Baixo Engajamento ({(1-proba):.1%} de confian√ßa)")
                
                # Gr√°fico de probabilidade
                fig, ax = plt.subplots(figsize=(8, 2))
                ax.barh(['Probabilidade'], [proba], color='#4ECDC4' if prediction == 1 else '#FF6B6B')
                ax.set_xlim(0, 1)
                ax.axvline(0.5, color='gray', linestyle='--')
                st.pyplot(fig)
                
            except Exception as e:
                st.error(f"Erro na previs√£o: {str(e)}")
                st.info("""
                Poss√≠veis solu√ß√µes:
                1. Recrie o modelo garantindo que 'EngagementLevel' seja apenas a target
                2. Verifique se todas as features est√£o na ordem correta
                """)
# Rodap√©
st.markdown("---")
st.caption("Desenvolvido com base nas an√°lises de pr√©-processamento do notebook dispon√≠veis no [GitHub](https://github.com/thaisar13/Game-Engagement-Level)")
